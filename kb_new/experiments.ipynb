{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19f2f8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bfbed7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is from the \"eval.py\" file.\n",
    "def set_seed(seed: int):\n",
    "    torch.manual_seed(seed)\n",
    "    # NOTE: this only sets on current cuda device\n",
    "    torch.cuda.manual_seed(seed)\n",
    "\n",
    "    \n",
    "def load_original_model_and_inputs(\n",
    "    model_original_src: str, context: dict\n",
    ") -> tuple[nn.Module, callable, callable]:\n",
    "    \"\"\"\n",
    "    Load class from original NN.module pytorch code\n",
    "    this is pytorch reference and we feed that to model to see if there will be any improvement\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        compile(model_original_src, \"<string>\", \"exec\")\n",
    "    except SyntaxError as e:\n",
    "        print(f\"Syntax Error in original code {e}\")\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        exec(model_original_src, context)  # expose to current namespace\n",
    "    except Exception as e:\n",
    "        print(f\"Error in executing original code {e}\")\n",
    "        return None\n",
    "\n",
    "    # these should be defined in the original model code and present in the context\n",
    "    get_init_inputs_fn = context.get(\"get_init_inputs\")\n",
    "    get_inputs_fn = context.get(\"get_inputs\")\n",
    "    Model = context.get(\"Model\")\n",
    "    return (Model, get_init_inputs_fn, get_inputs_fn)\n",
    "\n",
    "def time_execution_with_cuda_event(\n",
    "    kernel_fn: callable,\n",
    "    *args,\n",
    "    num_warmup: int = 3,\n",
    "    num_trials: int = 10,\n",
    "    verbose: bool = True,\n",
    "    device: torch.device = None,\n",
    ") -> list[float]:\n",
    "    \"\"\"\n",
    "    Time a CUDA kernel function over multiple trials using torch.cuda.Event\n",
    "\n",
    "    Args:\n",
    "        kernel_fn: Function to time\n",
    "        *args: Arguments to pass to kernel_fn\n",
    "        num_trials: Number of timing trials to run\n",
    "        verbose: Whether to print per-trial timing info\n",
    "        device: CUDA device to use, if None, use current device\n",
    "\n",
    "    Returns:\n",
    "        List of elapsed times in milliseconds\n",
    "    \"\"\"\n",
    "    if device is None:\n",
    "        if verbose:\n",
    "            print(f\"Using current device: {torch.cuda.current_device()}\")\n",
    "        device = torch.cuda.current_device()\n",
    "\n",
    "    # Warm ups\n",
    "    for _ in range(num_warmup):\n",
    "        kernel_fn(*args)\n",
    "        torch.cuda.synchronize(device=device)\n",
    "\n",
    "    print(\n",
    "        f\"[Profiling] Using device: {device} {torch.cuda.get_device_name(device)}, warm up {num_warmup}, trials {num_trials}\"\n",
    "    )\n",
    "    elapsed_times = []\n",
    "\n",
    "    # Actual trials\n",
    "    for trial in range(num_trials):\n",
    "        # create event marker default is not interprocess\n",
    "        start_event = torch.cuda.Event(enable_timing=True)\n",
    "        end_event = torch.cuda.Event(enable_timing=True)\n",
    "\n",
    "        start_event.record()\n",
    "        kernel_fn(*args)\n",
    "        end_event.record()\n",
    "\n",
    "        # Synchronize to ensure the events have completed\n",
    "        torch.cuda.synchronize(device=device)\n",
    "\n",
    "        # Calculate the elapsed time in milliseconds\n",
    "        elapsed_time_ms = start_event.elapsed_time(end_event)\n",
    "        if verbose:\n",
    "            print(f\"Trial {trial + 1}: {elapsed_time_ms:.3g} ms\")\n",
    "        elapsed_times.append(elapsed_time_ms)\n",
    "\n",
    "    return elapsed_times\n",
    "\n",
    "def get_timing_stats(elapsed_times: list[float], device: torch.device = None) -> dict:\n",
    "    \"\"\"Get timing statistics from a list of elapsed times.\n",
    "\n",
    "    Args:\n",
    "        elapsed_times: List of elapsed times in milliseconds\n",
    "        device: CUDA device, record device info\n",
    "    Returns:\n",
    "        Dict containing mean, std, min, max and num_trials\n",
    "        all timing are in ms\n",
    "    \"\"\"\n",
    "\n",
    "    stats = {\n",
    "        \"mean\": float(f\"{np.mean(elapsed_times):.3g}\"),\n",
    "        \"std\": float(f\"{np.std(elapsed_times):.3g}\"),\n",
    "        \"min\": float(f\"{np.min(elapsed_times):.3g}\"),\n",
    "        \"max\": float(f\"{np.max(elapsed_times):.3g}\"),\n",
    "        \"num_trials\": len(elapsed_times),\n",
    "    }\n",
    "\n",
    "    if device:\n",
    "        stats[\"hardware\"] = torch.cuda.get_device_name(device=device)\n",
    "        stats[\"device\"] = str(device)  # for debugging\n",
    "\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c343e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the original file \"generate_baseline_time.py\"\n",
    "def measure_program_time(\n",
    "        ref_arch_name: str,\n",
    "        ref_arch_src: str, \n",
    "        num_trials: int = 100,\n",
    "        use_torch_compile: bool = False,\n",
    "        torch_compile_backend: str=\"inductor\", \n",
    "        torch_compile_options: str=\"default\",\n",
    "        device: torch.device=\"cuda:0\",\n",
    "        verbose: bool = False,\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Measure the time of a KernelBench reference architecture\n",
    "    \"\"\"\n",
    "    context = {}\n",
    "    Model, get_init_inputs, get_inputs = load_original_model_and_inputs(\n",
    "        ref_arch_src, context\n",
    "    )\n",
    "    try:\n",
    "        with torch.no_grad():\n",
    "            torch.cuda.synchronize(device=device)\n",
    "            set_seed(42)\n",
    "            inputs = get_inputs()\n",
    "            set_seed(42)\n",
    "            init_inputs = get_init_inputs()\n",
    "            inputs = [\n",
    "                x.cuda(device=device) if isinstance(x, torch.Tensor) else x\n",
    "                for x in inputs\n",
    "            ]\n",
    "            init_inputs = [\n",
    "                x.cuda(device=device) if isinstance(x, torch.Tensor) else x\n",
    "                for x in init_inputs\n",
    "            ]\n",
    "\n",
    "            # Initialize PyTorch model, use this for eager mode execution\n",
    "            model = Model(*init_inputs)\n",
    "            \n",
    "            if use_torch_compile:\n",
    "                print(f\"Using torch.compile to compile model {ref_arch_name} with {torch_compile_backend} backend and {torch_compile_options} mode\")\n",
    "                model = torch.compile(model, backend=torch_compile_backend, mode=torch_compile_options)\n",
    "            else:\n",
    "                print(f\"Using PyTorch Eager Execution on {ref_arch_name}\")\n",
    "            \n",
    "            model = model.cuda(device=device)\n",
    "            torch.cuda.synchronize(device=device)\n",
    "            elapsed_times = time_execution_with_cuda_event(\n",
    "                model, *inputs, num_trials=num_trials, verbose=verbose, device=device\n",
    "            )\n",
    "            runtime_stats = get_timing_stats(elapsed_times, device=device)\n",
    "\n",
    "            if verbose:\n",
    "                print(f\"{ref_arch_name} {runtime_stats}\")\n",
    "            \n",
    "            return runtime_stats\n",
    "    except Exception as e:\n",
    "        print(f\"[Eval] Error in Measuring Performance: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98287bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Additional Functions (eval.py and others?)\n",
    "def graceful_eval_cleanup(curr_context: dict, device: torch.device):\n",
    "    \"\"\"\n",
    "    Clean up env, gpu cache, and compiled CUDA extensions after evaluation\n",
    "    \"\"\"  # delete ran-specific function definitions before next eval run\n",
    "    del curr_context\n",
    "    # Clear CUDA cache and reset GPU state\n",
    "    with torch.cuda.device(device):\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        # does this help?\n",
    "        torch.cuda.reset_peak_memory_stats(device=device)\n",
    "\n",
    "        torch.cuda.synchronize(\n",
    "            device=device\n",
    "        )  # Wait for all CUDA operations to complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "13c0c50b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch Eager Execution on 100_HingeLoss\n",
      "[Profiling] Using device: cuda:0 NVIDIA A40, warm up 3, trials 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/100 [00:13<21:27, 13.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch Eager Execution on 10_3D_tensor_matrix_multiplication\n",
      "[Profiling] Using device: cuda:0 NVIDIA A40, warm up 3, trials 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 2/100 [00:13<09:28,  5.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch Eager Execution on 11_4D_tensor_matrix_multiplication\n",
      "[Profiling] Using device: cuda:0 NVIDIA A40, warm up 3, trials 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 3/100 [00:17<08:11,  5.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch Eager Execution on 12_Matmul_with_diagonal_matrices_\n",
      "[Profiling] Using device: cuda:0 NVIDIA A40, warm up 3, trials 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 4/100 [00:18<05:25,  3.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch Eager Execution on 13_Matmul_for_symmetric_matrices\n",
      "[Profiling] Using device: cuda:0 NVIDIA A40, warm up 3, trials 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 5/100 [00:19<04:02,  2.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch Eager Execution on 14_Matmul_for_upper_triangular_matrices\n",
      "[Profiling] Using device: cuda:0 NVIDIA A40, warm up 3, trials 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 6/100 [00:20<03:06,  1.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch Eager Execution on 15_Matmul_for_lower_triangular_matrices\n",
      "[Profiling] Using device: cuda:0 NVIDIA A40, warm up 3, trials 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 7/100 [00:21<02:34,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch Eager Execution on 16_Matmul_with_transposed_A\n",
      "[Profiling] Using device: cuda:0 NVIDIA A40, warm up 3, trials 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 8/100 [00:22<02:14,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch Eager Execution on 17_Matmul_with_transposed_B\n",
      "[Profiling] Using device: cuda:0 NVIDIA A40, warm up 3, trials 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 9/100 [00:23<02:04,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch Eager Execution on 18_Matmul_with_transposed_both\n",
      "[Profiling] Using device: cuda:0 NVIDIA A40, warm up 3, trials 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 10/100 [00:24<01:52,  1.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch Eager Execution on 19_ReLU\n",
      "[Profiling] Using device: cuda:0 NVIDIA A40, warm up 3, trials 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 11/100 [00:37<07:11,  4.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch Eager Execution on 1_Square_matrix_multiplication_\n",
      "[Profiling] Using device: cuda:0 NVIDIA A40, warm up 3, trials 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 12/100 [00:38<05:18,  3.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch Eager Execution on 20_LeakyReLU\n",
      "[Profiling] Using device: cuda:0 NVIDIA A40, warm up 3, trials 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 13/100 [00:51<09:20,  6.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch Eager Execution on 21_Sigmoid\n",
      "[Profiling] Using device: cuda:0 NVIDIA A40, warm up 3, trials 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 14/100 [01:04<12:03,  8.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch Eager Execution on 22_Tanh\n",
      "[Profiling] Using device: cuda:0 NVIDIA A40, warm up 3, trials 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 15/100 [01:17<13:42,  9.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch Eager Execution on 23_Softmax\n",
      "[Profiling] Using device: cuda:0 NVIDIA A40, warm up 3, trials 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 16/100 [01:31<15:28, 11.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch Eager Execution on 24_LogSoftmax\n",
      "[Profiling] Using device: cuda:0 NVIDIA A40, warm up 3, trials 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 17/100 [01:46<16:44, 12.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch Eager Execution on 25_Swish\n",
      "[Profiling] Using device: cuda:0 NVIDIA A40, warm up 3, trials 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 18/100 [02:01<18:07, 13.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch Eager Execution on 26_GELU_\n",
      "[Profiling] Using device: cuda:0 NVIDIA A40, warm up 3, trials 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 19/100 [02:14<17:35, 13.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch Eager Execution on 27_SELU_\n",
      "[Profiling] Using device: cuda:0 NVIDIA A40, warm up 3, trials 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 20/100 [02:27<17:13, 12.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch Eager Execution on 28_HardSigmoid\n",
      "[Profiling] Using device: cuda:0 NVIDIA A40, warm up 3, trials 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 21/100 [02:39<16:48, 12.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch Eager Execution on 29_Softplus\n",
      "[Profiling] Using device: cuda:0 NVIDIA A40, warm up 3, trials 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 22/100 [02:52<16:44, 12.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch Eager Execution on 2_Standard_matrix_multiplication_\n",
      "[Profiling] Using device: cuda:0 NVIDIA A40, warm up 3, trials 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 23/100 [02:53<11:56,  9.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch Eager Execution on 30_Softsign\n",
      "[Profiling] Using device: cuda:0 NVIDIA A40, warm up 3, trials 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 24/100 [03:12<15:19, 12.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch Eager Execution on 31_ELU\n",
      "[Profiling] Using device: cuda:0 NVIDIA A40, warm up 3, trials 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 25/100 [03:24<15:09, 12.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch Eager Execution on 32_HardTanh\n",
      "[Profiling] Using device: cuda:0 NVIDIA A40, warm up 3, trials 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 26/100 [03:36<15:05, 12.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch Eager Execution on 33_BatchNorm\n",
      "[Profiling] Using device: cuda:0 NVIDIA A40, warm up 3, trials 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 27/100 [03:46<13:46, 11.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch Eager Execution on 34_InstanceNorm\n",
      "[Profiling] Using device: cuda:0 NVIDIA A40, warm up 3, trials 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 28/100 [04:02<15:24, 12.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch Eager Execution on 35_GroupNorm_\n",
      "[Profiling] Using device: cuda:0 NVIDIA A40, warm up 3, trials 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 29/100 [04:18<16:24, 13.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch Eager Execution on 36_RMSNorm_\n",
      "[Profiling] Using device: cuda:0 NVIDIA A40, warm up 3, trials 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 30/100 [04:38<18:11, 15.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch Eager Execution on 37_FrobeniusNorm_\n",
      "[Profiling] Using device: cuda:0 NVIDIA A40, warm up 3, trials 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 31/100 [04:54<18:08, 15.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch Eager Execution on 38_L1Norm_\n",
      "[Profiling] Using device: cuda:0 NVIDIA A40, warm up 3, trials 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 32/100 [05:16<20:06, 17.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch Eager Execution on 39_L2Norm_\n",
      "[Profiling] Using device: cuda:0 NVIDIA A40, warm up 3, trials 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 33/100 [05:35<19:58, 17.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch Eager Execution on 3_Batched_matrix_multiplication\n",
      "[Profiling] Using device: cuda:0 NVIDIA A40, warm up 3, trials 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 34/100 [05:38<14:53, 13.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch Eager Execution on 40_LayerNorm\n",
      "[Profiling] Using device: cuda:0 NVIDIA A40, warm up 3, trials 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 35/100 [05:39<10:42,  9.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch Eager Execution on 41_Max_Pooling_1D\n",
      "[Profiling] Using device: cuda:0 NVIDIA A40, warm up 3, trials 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 36/100 [05:47<09:48,  9.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch Eager Execution on 42_Max_Pooling_2D\n",
      "[Profiling] Using device: cuda:0 NVIDIA A40, warm up 3, trials 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 37/100 [05:52<08:24,  8.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch Eager Execution on 43_Max_Pooling_3D\n",
      "[Profiling] Using device: cuda:0 NVIDIA A40, warm up 3, trials 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 38/100 [06:00<08:05,  7.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch Eager Execution on 44_Average_Pooling_1D\n",
      "[Profiling] Using device: cuda:0 NVIDIA A40, warm up 3, trials 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 39/100 [06:05<07:12,  7.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch Eager Execution on 45_Average_Pooling_2D\n",
      "[Profiling] Using device: cuda:0 NVIDIA A40, warm up 3, trials 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 40/100 [06:36<14:11, 14.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch Eager Execution on 46_Average_Pooling_3D\n",
      "[Profiling] Using device: cuda:0 NVIDIA A40, warm up 3, trials 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 41/100 [06:51<14:08, 14.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch Eager Execution on 47_Sum_reduction_over_a_dimension\n",
      "[Profiling] Using device: cuda:0 NVIDIA A40, warm up 3, trials 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 42/100 [07:06<14:03, 14.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch Eager Execution on 48_Mean_reduction_over_a_dimension\n",
      "[Profiling] Using device: cuda:0 NVIDIA A40, warm up 3, trials 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 43/100 [07:21<14:10, 14.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch Eager Execution on 49_Max_reduction_over_a_dimension\n",
      "[Profiling] Using device: cuda:0 NVIDIA A40, warm up 3, trials 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 44/100 [07:36<13:54, 14.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch Eager Execution on 4_Matrix_vector_multiplication_\n",
      "[Profiling] Using device: cuda:0 NVIDIA A40, warm up 3, trials 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 45/100 [07:53<14:03, 15.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch Eager Execution on 50_conv_standard_2D__square_input__square_kernel\n",
      "[Profiling] Using device: cuda:0 NVIDIA A40, warm up 3, trials 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 46/100 [07:54<10:05, 11.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch Eager Execution on 51_Argmax_over_a_dimension\n",
      "[Profiling] Using device: cuda:0 NVIDIA A40, warm up 3, trials 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 47/100 [08:10<11:04, 12.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch Eager Execution on 52_Argmin_over_a_dimension\n",
      "[Profiling] Using device: cuda:0 NVIDIA A40, warm up 3, trials 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 48/100 [08:25<11:34, 13.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch Eager Execution on 53_Min_reduction_over_a_dimension\n",
      "[Profiling] Using device: cuda:0 NVIDIA A40, warm up 3, trials 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 49/100 [08:40<11:50, 13.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch Eager Execution on 54_conv_standard_3D__square_input__square_kernel\n",
      "[Profiling] Using device: cuda:0 NVIDIA A40, warm up 3, trials 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 50/100 [08:41<08:18,  9.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch Eager Execution on 55_conv_standard_2D__asymmetric_input__square_kernel\n",
      "[Profiling] Using device: cuda:0 NVIDIA A40, warm up 3, trials 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 51/100 [08:45<06:34,  8.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch Eager Execution on 56_conv_standard_2D__asymmetric_input__asymmetric_kernel\n",
      "[Profiling] Using device: cuda:0 NVIDIA A40, warm up 3, trials 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 52/100 [08:46<04:57,  6.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch Eager Execution on 57_conv_transposed_2D__square_input__square_kernel\n",
      "[Profiling] Using device: cuda:0 NVIDIA A40, warm up 3, trials 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 53/100 [08:54<05:04,  6.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch Eager Execution on 58_conv_transposed_3D__asymmetric_input__asymmetric_kernel\n",
      "[Profiling] Using device: cuda:0 NVIDIA A40, warm up 3, trials 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 54/100 [08:56<03:55,  5.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch Eager Execution on 59_conv_standard_3D__asymmetric_input__square_kernel\n",
      "[Profiling] Using device: cuda:0 NVIDIA A40, warm up 3, trials 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 55/100 [09:04<04:30,  6.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch Eager Execution on 5_Matrix_scalar_multiplication\n",
      "[Profiling] Using device: cuda:0 NVIDIA A40, warm up 3, trials 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 56/100 [09:12<04:52,  6.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch Eager Execution on 60_conv_standard_3D__square_input__asymmetric_kernel\n",
      "[Profiling] Using device: cuda:0 NVIDIA A40, warm up 3, trials 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 57/100 [09:13<03:33,  4.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch Eager Execution on 61_conv_transposed_3D__square_input__square_kernel\n",
      "[Profiling] Using device: cuda:0 NVIDIA A40, warm up 3, trials 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 58/100 [09:15<02:52,  4.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch Eager Execution on 62_conv_standard_2D__square_input__asymmetric_kernel\n",
      "[Profiling] Using device: cuda:0 NVIDIA A40, warm up 3, trials 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 59/100 [09:16<02:15,  3.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch Eager Execution on 63_conv_standard_2D__square_input__square_kernel\n",
      "[Profiling] Using device: cuda:0 NVIDIA A40, warm up 3, trials 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 60/100 [09:22<02:43,  4.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch Eager Execution on 64_conv_transposed_1D\n",
      "[Profiling] Using device: cuda:0 NVIDIA A40, warm up 3, trials 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 61/100 [09:28<03:01,  4.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch Eager Execution on 65_conv_transposed_2D__square_input__asymmetric_kernel\n",
      "[Profiling] Using device: cuda:0 NVIDIA A40, warm up 3, trials 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 62/100 [09:30<02:25,  3.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch Eager Execution on 66_conv_standard_3D__asymmetric_input__asymmetric_kernel\n",
      "[Profiling] Using device: cuda:0 NVIDIA A40, warm up 3, trials 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 63/100 [09:31<01:44,  2.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch Eager Execution on 67_conv_standard_1D\n",
      "[Profiling] Using device: cuda:0 NVIDIA A40, warm up 3, trials 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 64/100 [09:33<01:41,  2.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch Eager Execution on 68_conv_transposed_3D__square_input__asymmetric_kernel\n",
      "[Profiling] Using device: cuda:0 NVIDIA A40, warm up 3, trials 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 65/100 [10:13<08:07, 13.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch Eager Execution on 69_conv_transposed_2D__asymmetric_input__asymmetric_kernel\n",
      "[Profiling] Using device: cuda:0 NVIDIA A40, warm up 3, trials 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 66/100 [10:16<05:55, 10.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch Eager Execution on 6_Matmul_with_large_K_dimension_\n",
      "[Profiling] Using device: cuda:0 NVIDIA A40, warm up 3, trials 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 67/100 [10:18<04:25,  8.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch Eager Execution on 70_conv_transposed_3D__asymmetric_input__square_kernel\n",
      "[Profiling] Using device: cuda:0 NVIDIA A40, warm up 3, trials 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 68/100 [10:25<04:06,  7.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch Eager Execution on 71_conv_transposed_2D__asymmetric_input__square_kernel\n",
      "[Profiling] Using device: cuda:0 NVIDIA A40, warm up 3, trials 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 69/100 [10:27<03:02,  5.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch Eager Execution on 72_conv_transposed_3D_asymmetric_input_asymmetric_kernel___strided_padded_grouped_\n",
      "[Profiling] Using device: cuda:0 NVIDIA A40, warm up 3, trials 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 70/100 [10:27<02:08,  4.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch Eager Execution on 73_conv_transposed_3D_asymmetric_input_square_kernel__strided_padded__grouped\n",
      "[Profiling] Using device: cuda:0 NVIDIA A40, warm up 3, trials 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 71/100 [10:29<01:41,  3.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch Eager Execution on 74_conv_transposed_1D_dilated\n",
      "[Profiling] Using device: cuda:0 NVIDIA A40, warm up 3, trials 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 72/100 [10:31<01:24,  3.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch Eager Execution on 75_conv_transposed_2D_asymmetric_input_asymmetric_kernel_strided__grouped____padded____dilated__\n",
      "[Profiling] Using device: cuda:0 NVIDIA A40, warm up 3, trials 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 73/100 [10:32<01:09,  2.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch Eager Execution on 76_conv_standard_1D_dilated_strided__\n",
      "[Profiling] Using device: cuda:0 NVIDIA A40, warm up 3, trials 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 74/100 [10:50<03:08,  7.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch Eager Execution on 77_conv_transposed_3D_square_input_square_kernel___padded____dilated____strided__\n",
      "[Profiling] Using device: cuda:0 NVIDIA A40, warm up 3, trials 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 75/100 [10:51<02:11,  5.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch Eager Execution on 78_conv_transposed_2D_asymmetric_input_asymmetric_kernel___padded__\n",
      "[Profiling] Using device: cuda:0 NVIDIA A40, warm up 3, trials 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 76/100 [10:54<01:49,  4.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch Eager Execution on 79_conv_transposed_1D_asymmetric_input_square_kernel___padded____strided____dilated__\n",
      "[Profiling] Using device: cuda:0 NVIDIA A40, warm up 3, trials 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 77/100 [10:55<01:22,  3.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch Eager Execution on 7_Matmul_with_small_K_dimension_\n",
      "[Profiling] Using device: cuda:0 NVIDIA A40, warm up 3, trials 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 78/100 [10:56<01:03,  2.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch Eager Execution on 80_conv_standard_2D_square_input_asymmetric_kernel___dilated____padded__\n",
      "[Profiling] Using device: cuda:0 NVIDIA A40, warm up 3, trials 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 79/100 [10:58<00:51,  2.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch Eager Execution on 81_conv_transposed_2D_asymmetric_input_square_kernel___dilated____padded____strided__\n",
      "[Profiling] Using device: cuda:0 NVIDIA A40, warm up 3, trials 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 80/100 [10:59<00:37,  1.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch Eager Execution on 82_conv_depthwise_2D_square_input_square_kernel\n",
      "[Profiling] Using device: cuda:0 NVIDIA A40, warm up 3, trials 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 81/100 [11:01<00:41,  2.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch Eager Execution on 83_conv_depthwise_2D_square_input_asymmetric_kernel\n",
      "[Profiling] Using device: cuda:0 NVIDIA A40, warm up 3, trials 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 82/100 [11:03<00:34,  1.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch Eager Execution on 84_conv_depthwise_2D_asymmetric_input_square_kernel\n",
      "[Profiling] Using device: cuda:0 NVIDIA A40, warm up 3, trials 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 83/100 [11:13<01:14,  4.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch Eager Execution on 85_conv_depthwise_2D_asymmetric_input_asymmetric_kernel\n",
      "[Profiling] Using device: cuda:0 NVIDIA A40, warm up 3, trials 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 84/100 [11:14<00:56,  3.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch Eager Execution on 86_conv_depthwise_separable_2D\n",
      "[Profiling] Using device: cuda:0 NVIDIA A40, warm up 3, trials 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 85/100 [11:18<00:52,  3.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch Eager Execution on 87_conv_pointwise_2D\n",
      "[Profiling] Using device: cuda:0 NVIDIA A40, warm up 3, trials 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 86/100 [11:28<01:17,  5.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch Eager Execution on 88_MinGPTNewGelu\n",
      "[Profiling] Using device: cuda:0 NVIDIA A40, warm up 3, trials 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 87/100 [11:30<00:56,  4.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch Eager Execution on 89_cumsum\n",
      "[Profiling] Using device: cuda:0 NVIDIA A40, warm up 3, trials 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 88/100 [11:39<01:10,  5.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch Eager Execution on 8_Matmul_with_irregular_shapes_\n",
      "[Profiling] Using device: cuda:0 NVIDIA A40, warm up 3, trials 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 89/100 [11:41<00:50,  4.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch Eager Execution on 90_cumprod\n",
      "[Profiling] Using device: cuda:0 NVIDIA A40, warm up 3, trials 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 90/100 [11:50<01:00,  6.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch Eager Execution on 91_cumsum_reverse\n",
      "[Profiling] Using device: cuda:0 NVIDIA A40, warm up 3, trials 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 91/100 [12:02<01:10,  7.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch Eager Execution on 92_cumsum_exclusive\n",
      "[Profiling] Using device: cuda:0 NVIDIA A40, warm up 3, trials 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 92/100 [12:13<01:10,  8.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch Eager Execution on 93_masked_cumsum\n",
      "[Profiling] Using device: cuda:0 NVIDIA A40, warm up 3, trials 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 93/100 [12:33<01:25, 12.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch Eager Execution on 94_MSELoss\n",
      "[Profiling] Using device: cuda:0 NVIDIA A40, warm up 3, trials 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 94/100 [12:53<01:26, 14.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch Eager Execution on 95_CrossEntropyLoss\n",
      "[Profiling] Using device: cuda:0 NVIDIA A40, warm up 3, trials 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 95/100 [12:54<00:52, 10.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch Eager Execution on 96_HuberLoss\n",
      "[Profiling] Using device: cuda:0 NVIDIA A40, warm up 3, trials 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 96/100 [13:13<00:51, 12.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch Eager Execution on 97_ScaledDotProductAttention\n",
      "[Profiling] Using device: cuda:0 NVIDIA A40, warm up 3, trials 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 97/100 [13:16<00:30, 10.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch Eager Execution on 98_KLDivLoss\n",
      "[Profiling] Using device: cuda:0 NVIDIA A40, warm up 3, trials 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 98/100 [13:23<00:18,  9.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch Eager Execution on 99_TripletMarginLoss\n",
      "[Profiling] Using device: cuda:0 NVIDIA A40, warm up 3, trials 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 99/100 [13:31<00:08,  8.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch Eager Execution on 9_Tall_skinny_matrix_multiplication_\n",
      "[Profiling] Using device: cuda:0 NVIDIA A40, warm up 3, trials 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [13:32<00:00,  8.12s/it]\n"
     ]
    }
   ],
   "source": [
    "TIMING_DIR = \"./timings\"\n",
    "ds = load_dataset(\"ai-nikolai/KernelBench\")\n",
    "\n",
    "#SOME INIT PARAMS\n",
    "file_name: str=\"baseline_time.json\"\n",
    "num_trials: int= 100\n",
    "\n",
    "use_torch_compile: bool = False\n",
    "torch_compile_backend: str=\"inductor\"\n",
    "torch_compile_options: str=\"default\"\n",
    "\n",
    "device = torch.device(\"cuda:0\")\n",
    "json_results = {}\n",
    "\n",
    "#\n",
    "level=1\n",
    "level_1 = ds[f\"level_{level}\"]\n",
    "num_problems = len(level_1)\n",
    "\n",
    "json_results[f\"level_{level}\"]={}\n",
    "\n",
    "for sample in tqdm.tqdm(level_1):\n",
    "    ref_arch_src, ref_arch_name  = sample[\"code\"], sample[\"name\"]\n",
    "    runtime_stats = measure_program_time(\n",
    "        ref_arch_name=ref_arch_name,\n",
    "        ref_arch_src=ref_arch_src,\n",
    "        use_torch_compile=use_torch_compile,\n",
    "        torch_compile_backend=torch_compile_backend,\n",
    "        torch_compile_options=torch_compile_options,\n",
    "        device=device,\n",
    "        verbose=False, # do not print \n",
    "        num_trials=num_trials,\n",
    "    )\n",
    "    json_results[f\"level_{level}\"][ref_arch_name] = runtime_stats\n",
    "\n",
    "save_path = os.path.join(TIMING_DIR, file_name)\n",
    "os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "\n",
    "with open(save_path, \"w\") as f:\n",
    "    json.dump(json_results, f)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_kb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
